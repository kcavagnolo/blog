---
layout: post
title: Spinning-up a Spark Instance on AWS
author: Ken Cavagnolo
category : lessons
tags: [spark, python, aws, osx]
comments: true
tweets: true
---

{% include JB/setup %}

<div class="blurb">

<p>I rely on reference material in most of my work. There are two reasons
for this:
<ul>
<li>1. I have a memory leak.</li>
<li>2. I learned in grad school that it's more important how one thinks
rather than what one knows.</li>
</ul></p>

<p>Point two requires a caveat because base knowledge forms the first
step in thinking through a problem; for example, while recalling from
memory the formulae for scattering may not be valuable in explaining
why the sky is blue, knowing that it is in some way related to
scattering requires a base knowledge about physics, e.g. subject
matter expertise.</p>

<p>The above is a long-winded way of saying that when I am tackling a
new project, I love searching for Stackoverflow posts or blogs that
explain a method in simple steps. As a data science person, these
resources are exceptionally useful for what many developers consider
trivial or obvious processes, for example setting up a Spark cluster
on AWS.</p>

<p>First things first, check out the <a
href="https://aws.amazon.com/articles/Elastic-MapReduce/4926593393724923"
target="_blank">AWS guides</a> and <a
href="https://aws-portal.amazon.com/gp/aws/developer/registration/index.html"
target="_blank">create an AWS account</a>.</p>

<p>Some basic steps you'll need to complete are:
<ul>
<li>Create a keypair locally ssh-keygen</li>
<li>Import keypair to your AWS account</li>
<li>Install the AWS <a href="http://aws.amazon.com/cli/" target="_blank">command line interface (CLI)</a> locally</li>
<li>Setup your local environment variables so AWS can be accessed via the CLI easily</li>
</ul></p>


build cluster:
aws emr create-cluster --name SparkCluster --ami-version 3.2 --instance-type m3.xlarge --instance-count 3 --ec2-attributes KeyName=MYKEY --applications Name=Hive --bootstrap-actions Path=s3://support.elasticmapreduce/spark/install-spark

check that it's running: aws emr describe-cluster --cluster-id j-xxxxxxxxxx

connect to master node
aws emr ssh --cluster-id j-2C68SECCZGMM4 --key-pair-file ~/.ssh/id_rsa_aws

run some spark stuff using scala as the lang

</div>
